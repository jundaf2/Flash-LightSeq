Script started on 2022-10-12 22:22:52+0800
(base) ]0;poweruser@s-113-1-1: ~/junda.feng/ixinfer/TransformerInfer/build[01;32mpoweruser@s-113-1-1[00m:[01;34m~/junda.feng/ixinfer/TransformerInfer/build[00m$ ./TransfomrerInfer ../model_weights/transformer.pb 1 32[C[C[K[K1[C[1P 10 1
Parsing protobuf: ../model_weights/transformer.pb
Finish loading src_emb_wei from host to device
Finish loading trg_emb_wei from host to device
Finish loading enc_wei from host to device
Finish loading dec_wei from host to device
Finish loading all weight from host to device
***model config***
encoder layers: 8
decoder layers: 4
hidden size: 512
inner size: 2048
head number: 8
dim per head: 64
src vocab size: 5003
trg vocab size: 5003
is_post_ln: 0
no_scale_embedding: 0
use_gelu: 0
start_id: 5001
end_id: 5002
padding_id: 5003
multilg_type: 0

***generator config***
beam size: 1
max step: 64
extra decode length(max decode length - src input length): 0
length penalty: 0.6
diverse lambda: 0
sampling method: topk
topk: 32
topp: 0.75
Allocated 49MB GPU buffer for transformer
encoder buffer init start
encoder buffer init succeed
decoder buffer init start
decoder buffer init succeed
infer preprocessing finished
batch_size-1 batch_seq_len-6
batch_token_ids: 1, 2, 3, 4, 5, 6, 
launch encoder embedding kernel
emb out: token-0
emb out: -0.0150833, 0.0685425, -0.106201, 0.00239563, 0.398682, -0.286865, 0.314941, -0.265869, 0.153198, -0.279297, 
emb out: token-1
emb out: 0.320801, 0.648438, 0.632324, 1.08594, 0.52002, 0.284668, -0.324219, 0.87793, 0.930176, 1.09375, 
emb out: token-2
emb out: 0.386719, 1.30664, 1.16504, 0.727051, 0.981934, 0.657227, 1.63867, 1.0459, 0.832031, -0.708008, 
emb out: token-3
emb out: 0.324707, 0.287109, 0.512695, 0.138916, 0.640625, 0.786133, -0.0375977, 0.714355, 0.888184, 2.16797, 
emb out: token-4
emb out: -0.778809, -0.714355, -0.896484, -0.582031, -0.527832, -0.30249, 0.157349, -0.200928, 0.00512695, 1.28613, 
emb out: token-5
emb out: -0.854004, -0.850098, -1.14746, -1.61328, -0.500977, -1.0791, -0.970703, -1.11133, -1.09766, -0.216187, 
token embedding weight: 0.465576, 0.972656, -0.150146, -0.438477, -0.153198, -0.385986, -0.687012, 1.60547, 0.226685, 0.812012, 
position embedding weight: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
launch self-attention layer 0
cuBLAS GEMM non-fused Self-Attention: 648 microseconds
encoder attention output: 0.406738, 0.204224, 0.0457153, 0.0994263, -0.433838, -0.284424, 0.332275, 0.60791, 0.501953, 0.997559, -0.340332, 1.59766, -0.586914, 1.77148, -0.264404, 0.472168, -1.74121, 0.219849, -0.569336, -2.15625, -0.330811, -1.77344, 1.58301, -0.0493164, 1.81348, -2.57422, 6.0625, -0.680664, 0.458984, 1.90625, -2.86328, -1.35352, -1.77734, 0.170898, 0.746094, 1.46875, 1.05078, -3.5957, 4.41797, -0.651367, -5.17188, -3.45508, -6.67969, 2.25977, -0.129883, -3.68359, -7.00391, -7.01562, -3.64844, -8.3125, -11.1641, -1.59961, 4.61719, 0.541016, -2.53516, 1.05859, 1.57324, -7.19141, 0.793945, 4.16797, 0.435547, 2.92188, -2.32812, -2.29883, 
launch FFN layer 0
launch self-attention layer 1
cuBLAS GEMM non-fused Self-Attention: 74 microseconds
encoder attention output: -2.09766, -5.18359, -3.28906, 1.23438, -4.97656, -3.83789, 2.57422, -3.44141, -2.91992, -1.49219, 0.615234, 8.03125, 0.395508, -1.27344, -2.80859, 0.257324, -1.07812, 0.521484, -3.32422, -4.50781, -2.66406, -0.621094, -1.73047, -6.04688, -1.06055, -4.34375, 11.7188, -0.458008, -5.66797, 1.62207, -7.92969, 1.00879, -3.61328, -3.74219, -0.0654297, 3.0293, 1.7168, -6.76172, -0.585938, 1.41016, -10.7344, -5.89453, -10.4219, 2.14844, 1.53516, -3.24023, -10.0547, -11.4062, -8.44531, -13.9844, -15.7422, -3.45312, 6.23438, -0.404297, -3.70703, -2.0625, 2.21875, -11.7969, -1.13672, 6.30469, 2.84961, 4.90234, 1.08398, -4.88672, 
launch FFN layer 1
launch self-attention layer 2
cuBLAS GEMM non-fused Self-Attention: 71 microseconds
encoder attention output: -2.15039, -2.34766, 1.10352, 2.94922, -6.68359, -0.607422, 9.5, -5.27734, -7.51172, -5.69922, 2.46484, 8.89844, 3.04297, -3.30469, -3.28906, -1.21289, 3.44922, 1.05859, -1.70508, -11.0547, -1.08984, 1.99023, -6.38281, -8.82812, -4.46875, -3.29297, 14.7344, 0.868164, -6.30078, 8.375, -14.1094, 2.4668, -9.625, -10.2656, 1.94141, 5.41406, -0.263672, -6.82422, -6.05469, 0.640625, -21.2969, -12.0703, -11.1953, 3.96875, -3.70312, -2.88672, -18.5938, -12.2812, -12.2578, -15.125, -18.8906, -7.82812, 9.4375, 5.78906, 0.152344, -0.222656, 2.82422, -14.9141, 1.10156, 10.6328, 4.21094, 12.4375, 7.10547, -7.16406, 
launch FFN layer 2
launch self-attention layer 3
cuBLAS GEMM non-fused Self-Attention: 71 microseconds
encoder attention output: 4.03125, -5.73438, 2.59766, 4.875, -3.02734, -2.26953, 15.5156, -7.32031, -10.1406, -10.2344, 6.97266, 4.875, 8.40625, -7.38281, 0.505859, 7.10547, 9.01562, -6.19531, -6.38281, -18.9062, 3.3457, 3.05664, -10.8516, -8.97656, -10.7578, 1.0625, 15.875, 11.7578, -4.875, 12.125, -16.75, 2.60742, -15.7812, -20.8438, 0.285156, 5.00781, -6.33203, -10.2656, -5.24219, 1.37988, -25.0312, -16.7812, -9.1875, 8.73438, -7.23828, -2.23633, -25.4219, -14.6172, -19.4844, -13.2188, -18.5938, -9.55469, 7.82812, 4.67969, 5.25391, -2.45508, 6.28906, -21.2188, 2.50391, 21.9688, 8.28906, 18.5625, 9.11719, -0.53125, 
launch FFN layer 3
launch self-attention layer 4
cuBLAS GEMM non-fused Self-Attention: 72 microseconds
encoder attention output: 6.1875, -5.16797, 1.04199, 8.66406, -3.36914, -5.26172, 22.5938, -12.7812, -6.84766, -17.3125, 5.35156, 8.32031, 22.25, -6.58984, -1.46387, 11.4609, 13.25, -13.6484, -0.78125, -26.5156, -0.332031, 2.77539, -22.5312, -5.90234, -16.5938, 1.06055, 25.9531, 13.0234, -8.30469, 7.90625, -29.0625, 3.375, -14.875, -23.2656, 1.0332, 4.66016, -11.9062, -15.3516, -12.4688, 4.48828, -29.3281, -13.0391, -6.29688, 9.79688, -13.8438, -6.78906, -28.8438, -19.125, -19.9375, -8.70312, -12.7969, -1.36719, 3.875, 4.97656, 9.50781, -3.91797, 10.5391, -23.1875, 8.95312, 22.3281, 7.14844, 11.9844, 6.39062, 4.73438, 
launch FFN layer 4
launch self-attention layer 5
cuBLAS GEMM non-fused Self-Attention: 71 microseconds
encoder attention output: 4.65625, -8.5, 4.74219, 7.64453, -7.78516, 1.97656, 28.3438, -20.75, -1.58594, -15.0234, 7.14844, 1.71094, 34.4062, -3.78906, -4.41797, 11.2188, 8.92969, -11.0156, 1.7998, -35.1875, 2.00977, 2.28125, -23.125, 4.35938, -18.6875, -4.36328, 20.5, 11.3906, -17.9844, 16.3438, -32.2188, -4.19141, -17.1562, -27.1562, 5.53125, 21.0312, -21.5938, -22.125, -16.875, 8.65625, -36.3125, -24.2188, -0.457031, 11.9375, -18.4844, -0.65625, -34.6562, -16.1094, -21.2031, -1.36328, -8.04688, -2.8125, -5.64062, 10.3047, 2.81055, -3.44531, 13.9375, -13.0547, 15.2109, 28.6875, 12.4062, 2.89062, -0.625, 7.27344, 
launch FFN layer 5
launch self-attention layer 6
cuBLAS GEMM non-fused Self-Attention: 71 microseconds
encoder attention output: -10.1641, -18.3594, 15.1875, -4.71094, -12.4375, 15.5781, 30.5938, -8.57031, 7.89062, -4.20312, 5.14062, -2.61719, 40.75, -14.5781, 1.58008, 5.03125, 7.93359, -1.46094, 0.726562, -39.0938, 2.50781, 5.28906, -35.375, 23.9844, -21.0469, -4.08203, 22.6875, 5.03125, -22, 23.75, -29.9375, -15.9062, -19.0312, -29.75, 12.5781, 28.7812, -29.1562, -14.2109, -23.8594, 7.94922, -33.7812, -23, -5.21484, 13.5078, -23.9375, -9.69531, -37.3438, -20.25, -12.4844, -2.92578, -20.0312, -10.9688, -5.47266, 10.3281, -1.88867, -3.37109, 20.2188, -20.2656, 19.4531, 31.0156, 8.53125, -12.7734, -14.0312, 0.230469, 
launch FFN layer 6
launch self-attention layer 7
cuBLAS GEMM non-fused Self-Attention: 71 microseconds
encoder attention output: -13.6094, -19.6406, 30.5, 0.355469, -6.49219, 37.0312, 37.125, 3.32812, -5.49219, 5.90625, 1.69727, 7.45312, 54.25, -16.6562, -8.61719, 4.40234, 0.09375, -3.69141, 5.21094, -49.3438, 3.99414, 7.16406, -35.125, 41.8438, -27.25, -6.96875, 30.2812, 1.78125, -24.375, 23.125, -24.625, -21.75, -28.0625, -33.3125, 15.6094, 54.5938, -17.5312, -19.25, -23.75, 8.16406, -29.2188, -21.2969, -19.3438, 14.7969, -33.6875, -18.3125, -37.2188, -30.4844, -12.8438, -2.73047, -13.9531, -20.0625, -12.0625, 15.1562, -19.1875, -5.11328, 18, -20.6406, 17.6719, 42.4062, 10.0938, 3.77344, -27.4375, -6.96094, 
launch FFN layer 7
encoder output: token-0
encoder_output: -0.358887, -0.207642, 0.65332, 0.002491, 0.0822754, 0.700684, 0.641602, -0.0451965, -0.344482, 0.100281, 0.044281, 0.311523, 1.07715, -0.280273, -0.300537, -0.0696411, 0.0891113, -0.0761108, 0.0257874, -0.912598, -0.00785828, 0.361328, -0.566406, 0.578125, -0.508301, -0.184204, 0.727051, 0.427002, -0.536621, 0.376709, -0.470459, -0.243042, -0.522461, -0.766602, 0.124878, 0.966797, -0.359375, -0.418213, -0.51709, 0.128296, -0.861816, -0.347412, -0.427979, 0.272705, -0.482178, -0.244751, -0.688965, -0.615234, -0.16748, -0.00267029, -0.279785, -0.624512, -0.166626, 0.351562, -0.585449, -0.0368958, 0.247681, -0.24292, 0.339111, 0.738281, 0.0945435, -0.081543, -0.609863, -0.0248871, 
encoder output: token-1
encoder_output: -0.211914, 0.0171356, 0.272705, -0.0569153, -0.00908661, 0.735352, 0.0538025, -0.065979, 0.387939, 0.538086, -0.303223, -0.0425415, 1.09668, 0.0385437, -0.178101, -0.24646, 0.00467682, -0.361572, 0.203369, -0.503418, 0.559082, 0.446533, -0.24707, 0.223755, -0.654785, -0.0264282, 0.183472, -0.248291, -0.286133, 0.500488, -0.489014, -0.290039, -0.151367, -0.911621, 0.152954, 0.589355, -0.849121, 0.0378723, -0.481934, 0.349854, -0.375244, -0.789551, -0.124084, 0.512207, -0.110535, -0.387695, -0.662598, -0.365479, -0.449463, 0.455078, 0.0225525, 0.289551, 0.019455, -0.0483093, -0.258301, 0.154297, -0.0770874, -0.0424194, 0.207397, 0.267578, 0.119568, 0.18689, -0.361816, 0.23645, 
encoder output: token-2
encoder_output: 0.44458, 0.334473, 1.13867, 0.303955, 0.227051, 0.997559, 0.811035, -0.197266, -0.311035, 0.328125, 0.374756, 0.0293121, 0.892578, -0.393066, -0.151855, 0.210693, 0.589355, 0.0845337, 0.507812, -0.415771, 0.352295, 0.46582, -0.793945, 0.932617, -0.741699, -0.0981445, 0.747559, 0.157837, 0.432617, 0.447754, -0.69873, -0.144287, -0.416016, -0.320068, 0.168823, 1.12988, -0.807617, -0.192993, -0.352295, 0.262207, -0.496338, -0.575195, -0.201294, 0.370605, -0.37207, -0.203125, -0.702148, 0.0795288, -0.400879, 0.210938, -0.362061, 0.285156, 0.117065, 0.735352, -0.240723, -0.338135, 0.742188, -0.551758, 0.573242, 0.610352, 0.0945435, 0.135742, -0.944824, 0.400146, 
encoder output: token-3
encoder_output: -0.209839, 0.146973, 0.552734, 0.580566, 0.275635, 1.0293, 0.634766, 0.0670166, -0.048584, 1.10742, 0.192993, 0.0169678, 0.80127, -0.0930176, 0.285889, 0.388672, 0.775879, 0.143555, 0.178101, -0.0505066, 0.688477, 0.21521, -0.939941, 0.595215, -0.354004, 0.308838, -0.273438, -0.119141, 0.530273, 0.277588, 0.114441, 0.114868, -0.163818, -0.175049, 0.00568008, 1.02051, -0.773438, -0.0149689, -0.0213928, 0.261475, 0.0290833, -0.88916, -0.217407, 0.364502, -0.931152, -0.59082, -0.311523, -0.640137, 0.106567, 0.251465, 0.418213, -0.108215, -0.0397949, 0.629395, -0.289307, -0.199341, -0.475098, -0.107727, 0.987305, 0.363037, 0.16687, 0.146851, -0.524902, -0.107727, 
encoder output: token-4
encoder_output: -0.619629, 0.0957642, 0.125854, -0.136963, 0.120728, 0.884766, -0.0124664, 0.213013, 0.0689087, 0.0978394, -0.202148, 0.00208282, 0.612305, -0.0126801, -0.0355225, 0.274658, 0.0828247, 0.265137, 0.358643, -0.275879, 0.0930176, -0.0555115, -1.12109, 0.230347, -0.307861, 0.0473633, 0.577637, 0.380615, -0.353516, 0.0450439, 0.391113, 0.148926, 0.355469, -0.0984497, 0.408936, 0.827148, 0.266357, -0.0324097, -0.0831299, -0.1698, 0.0031147, -0.274658, -0.0367432, -0.00984955, -0.283936, 0.297363, -0.339111, -0.259277, -0.131226, 0.361572, 0.195801, 0.0435181, 0.310059, 0.0735474, -0.135986, -0.601074, 0.048584, -0.0795288, 0.771973, 0.041687, 0.0733032, 0.0609436, -0.144775, 0.39209, 
encoder output: token-5
encoder_output: -0.108459, 0.280029, 0.464111, -0.0839844, 0.0667114, 0.24231, -0.277344, 0.279785, -0.126953, -0.244507, -0.72998, -0.16272, 0.324219, 0.17688, 0.133423, 0.0941772, 0.0897217, -0.00664902, 0.00764847, -0.46582, 0.157715, 0.325928, -1.05762, 0.0575256, -0.661621, 0.723633, 0.458984, -0.206543, 0.0663452, 0.226807, 0.465332, 0.29248, 0.26709, -0.328125, 0.433838, 1.28418, 0.258789, 0.0586853, 0.00915527, 0.0708008, 0.112244, -0.363281, -0.0673828, 0.100769, -0.366211, 0.0681152, -0.216431, -0.429932, 0.0368347, 0.139526, 0.239624, 0.375488, 0.384766, 0.729004, 0.157471, -0.0708618, -0.335938, -0.359131, 0.860352, 0.00561905, 0.312744, 0.682617, -0.113098, 0.61084, 
_p_d_encoder_output(head):: -0.358887, -0.207642, 0.65332, 0.002491, 0.0822754, 
_p_d_encoder_output(tail): 1.00781, -1.11133, -0.16687, 0.382812, -0.390869, 
encoder project(head):: -0.306152, -0.644043, -0.0342407, -0.16687, 0.076416, -0.156494, -0.16272, 0.015976, -0.0116425, -0.417969, 
encoder out(head):: 2.96875, 1.14258, 1.2627, 4.80859, -0.476562, 
encoder out(tail):: 0.737305, -2.12695, -2.6582, -0.210938, -1.37109, 
*** run step 0 ***
decoder emb: batch-0, beam-0
emb: 0.00182629, 0.103638, 0.390869, 0.159424, -18.0938, 0.353516, 0.663086, -0.0861206, 0.976074, -0.0918579, 
self attn ln(head): : -0.0372925, -0.0215607, -0.017395, -0.00482941, 0.0398865, 
self attn ln(tail): : 0.0351868, -0.0314636, 0.0230103, -0.0551453, -0.0448914, 
self qkv(head): : -0.138428, -0.119873, -0.473633, 0.56543, 0.268311, 
self qkv(tail): : 0.0426941, -0.0317688, 0.0110168, 0.118896, -0.125732, 
self attn q(head): : -0.00683594, -0.185303, -0.708984, 0.485352, 0.191895, 
self attn q(tail): : -0.06427, 0.10907, 0.670898, 0.236694, 0.0507202, 
self attn k(head): : 1.7373, 0.192871, -0.489258, -0.595703, -2.20312, 
self attn k(tail): : -1.9668, -2.04492, -7.95312, 0.553711, -6.63672, 
self attn v(head): : 0.118713, -0.200195, 0.129395, -0.0739136, 0.0744629, 
self attn v(tail): : -0.0343933, -0.0805664, 0.107422, 0.104309, 0.0698242, 
self attn corr(head): : 1, 1, 1, 1, 1, 
self attn corr(tail): : 1, 1, 1, 1, 1, 
self attn before ffn(head): : 0.118713, -0.200195, 0.129395, -0.0739136, 0.0744629, 
self attn before ffn(tail): : -0.0343933, -0.0805664, 0.107422, 0.104309, 0.0698242, 
self attn out(head): : -0.234131, -0.0283508, 0.0227051, 
self attn out(tail): : -1.08594, 1.37305, 0.743164, 
encdec attn ln(head): : -0.0162201, -0.00386429, -0.0501709, -0.00765228, -0.566895, 
encdec attn ln(tail): : 0.0761719, -0.0423279, 0.025238, -0.0996704, -0.0570374, 
encdec attn ffn out(head): : -0.516602, -0.467773, 1.40137, 
encdec attn ffn out(tail): : -8.50781, -11.3125, 0.365479, 
ffn ln(head): : -0.145264, -0.269043, -0.249756, -0.250244, 1.22363, 
ffn ln(tail): : 0.310303, -0.115173, 0.185181, -0.37793, -0.265137, 
ffn ln(head): : 0.157471, -0.249023, 1.00781, -2.01562, -200.75, 
ffn ln(tail): : 4.85156, 4.17969, -9.45312, -12.25, 0.709473, 
self attn ln(head): : 0.00852203, -0.0201263, -0.0298767, -0.0438843, -0.011467, 
self attn ln(tail): : 0.0404663, -0.00800323, -0.0471497, -0.141357, -0.0537109, 
self qkv(head): : -0.495361, 0.14917, -0.033844, 0.0620117, -0.53125, 
self qkv(tail): : 0.217041, -0.592285, -0.299072, 0.282227, 0.281494, 
self attn q(head): : -0.428223, 0.114319, 0.117554, 0.130493, -0.429932, 
self attn q(tail): : 0.791504, -0.513672, -0.208984, 0.916016, 0.100098, 
self attn k(head): : -0.520508, 0.731445, 1.55469, -1.55078, 1.66211, 
self attn k(tail): : 0.996094, -0.545898, -2.08984, -0.182617, 0.18042, 
self attn v(head): : 0.52002, 0.0994263, 0.051239, -0.274658, -0.302246, 
self attn v(tail): : 0.318115, -1.0332, -0.382568, 0.201416, 0.150757, 
self attn corr(head): : 1, 1, 1, 1, 1, 
self attn corr(tail): : 1, 1, 1, 1, 1, 
self attn before ffn(head): : 0.52002, 0.0994263, 0.051239, -0.274658, -0.302246, 
self attn before ffn(tail): : 0.318115, -1.0332, -0.382568, 0.201416, 0.150757, 
self attn out(head): : 1.87891, 1.21289, 2.40039, 
self attn out(tail): : -6.66406, -14.6016, 0.097168, 
encdec attn ln(head): : -0.047821, 0.0421753, -0.0418396, 0.0634155, -0.042511, 
encdec attn ln(tail): : 0.017395, 0.0654297, -0.0116119, -0.138794, -0.0248413, 
encdec attn ffn out(head): : -15.9844, -4.21094, 8.78906, 
encdec attn ffn out(tail): : -11.5469, -18.625, -7.55469, 
ffn ln(head): : -0.414307, -0.205933, -0.314697, -0.163208, 2.33789, 
ffn ln(tail): : 0.337402, 0.73584, -0.0175323, -0.253418, -0.206177, 
ffn ln(head): : -17.25, -1.7666, 7.82031, -0.810547, -360.5, 
ffn ln(tail): : 11.8281, 5.24219, -11.5625, -17.6094, -4.58594, 
self attn ln(head): : -0.240479, -0.032959, 0.0440369, -0.0189056, 0.0296326, 
self attn ln(tail): : 0.0315552, -0.0286102, -0.0495911, -0.151001, -0.0678101, 
self qkv(head): : -0.286621, -0.227173, 0.916016, -0.57666, 0.155518, 
self qkv(tail): : 0.978516, -0.51416, -0.340576, -0.403809, 0.215332, 
self attn q(head): : -0.337891, -0.459229, 0.823242, -0.350098, -0.0456543, 
self attn q(tail): : -0.151367, 0.658203, -0.315674, 0.247803, -0.290283, 
self attn k(head): : 1.90234, 3.5, 0.600098, 1.37109, 4.42969, 
self attn k(tail): : -0.330078, -0.735352, -1.80078, -5.29297, -0.41333, 
self attn v(head): : 0.020752, -0.210571, 0.168823, -0.0142822, -0.158081, 
self attn v(tail): : 1.0332, -0.87793, -0.260498, -0.0231934, 0.0427246, 
self attn corr(head): : 1, 1, 1, 1, 1, 
self attn corr(tail): : 1, 1, 1, 1, 1, 
self attn before ffn(head): : 0.020752, -0.210571, 0.168823, -0.0142822, -0.158081, 
self attn before ffn(tail): : 1.0332, -0.87793, -0.260498, -0.0231934, 0.0427246, 
self attn out(head): : -19.1875, 2.625, 11.8281, 
self attn out(tail): : -7.71875, -22.0312, -8.15625, 
encdec attn ln(head): : -0.110168, 0.0258789, 0.0188446, 0.00171566, -0.052948, 
encdec attn ln(tail): : 0.0133972, -0.00294685, -0.0228271, -0.116516, -0.0520935, 
encdec attn ffn out(head): : -31.5938, 9.64844, 32.5312, 
encdec attn ffn out(tail): : -28.75, -27.0781, -15.9844, 
ffn ln(head): : -0.783691, -0.0855103, 0.425293, -0.021698, 0.773438, 
ffn ln(tail): : 0.409668, 0.0706177, -0.387695, -0.30957, -0.327637, 
ffn ln(head): : -35.5625, 13.6875, 30.5781, 1.31445, -567.5, 
ffn ln(tail): : 11.0781, -7.82812, -26.5781, -21.0938, -13.7188, 
self attn ln(head): : -0.467041, 0.0603027, 0.268799, 0.029129, 0.305176, 
self attn ln(tail): : -0.00324631, -0.109924, -0.155884, -0.177734, -0.161621, 
self qkv(head): : 0.512207, -0.45874, -0.0385132, -1.46289, 1.65039, 
self qkv(tail): : 1.10938, 1.24512, 0.0567017, 0.0222778, -1.69629, 
self attn q(head): : 0.621094, -0.460938, 0.297363, -1.45605, 1.33691, 
self attn q(tail): : 0.11145, -0.497314, 1.38281, -0.453857, 0.848145, 
self attn k(head): : 2.8418, -9.61719, 28.0469, 11.6875, -23, 
self attn k(tail): : -2.18555, 0.314209, -0.514648, -0.761719, -0.578613, 
self attn v(head): : 0.855469, 0.401367, -0.82373, 1.21484, -0.0864258, 
self attn v(tail): : 1.13477, 1.23926, -0.0222168, 0.366455, -1.69824, 
self attn corr(head): : 1, 1, 1, 1, 1, 
self attn corr(tail): : 1, 1, 1, 1, 1, 
self attn before ffn(head): : 0.855469, 0.401367, -0.82373, 1.21484, -0.0864258, 
self attn before ffn(tail): : 1.13477, 1.23926, -0.0222168, 0.366455, -1.69824, 
self attn out(head): : -30.625, 15.8984, 39.9062, 
self attn out(tail): : -31.3125, -11.3281, -14.6484, 
encdec attn ln(head): : -0.163574, 0.0839233, 0.158691, 0.0127869, 0.0769043, 
encdec attn ln(tail): : 0.0041008, -0.0563965, -0.10321, -0.0772095, -0.0996094, 
encdec attn ffn out(head): : -16.8906, 14.9219, 46.125, 
encdec attn ffn out(tail): : -53.875, -3.58203, -24.5469, 
ffn ln(head): : -0.407959, 0.0619812, 0.581543, 0.00761414, -5.14062, 
ffn ln(tail): : 1.01562, 0.0273895, -0.964355, -0.148438, -0.40625, 
ffn ln(head): : -14.75, 18.0938, 57.875, -4.89844, -565, 
ffn ln(tail): : 41.0938, -15.0469, -53.9375, 1.01172, -35.4375, 
decoder output: batch-0, beam-0
hidden: -0.838379, 0.794434, 1.82031, -0.0156097, 4.38672, -2.36914, -0.671387, 0.268799, 1.16016, -0.524414, 
logits: -36.0938, -38.2812, -36.0938, -36.5, -39.7812, -35.3438, -40.1875, -36.0625, -36.0625, -41.5625, 
ker_topk_sample_launcher with _cur_step=0  _max_step=64  _max_thread_per_block=256
### in ker_topk_sample_launcher 
### out ker_topk_sample_launcher 
unfinished flag: 1, 
Batch token ids: : 5001, 1, 
*** run step 1 ***
decoder emb: batch-0, beam-0
emb: 0.147461, 0.674805, 1.20703, 1.24121, -12.8672, 1.08203, 0.522461, -0.0473633, 2.05469, 1.03711, 
self attn ln(head): : 0.0725708, 0.219727, 0.253662, 0.344727, -0.0045166, 
self attn ln(tail): : -0.237549, -0.0266266, -0.117371, 0.114868, -0.0737305, 
self qkv(head): : 0.0709839, 0.678223, 1.43066, -1.08008, -2.81055, 
self qkv(tail): : 0.97998, -0.101379, 0.273926, 0.109009, 1.19238, 
self attn q(head): : 0.202637, 0.612793, 1.19531, -1.16016, -2.88672, 
self attn q(tail): : 0.439209, -0.906738, 1.23535, -1.64453, -0.427734, 
self attn k(head): : -0.271484, 2.7207, -1.05859, -0.328613, 0.121094, 
self attn k(tail): : -0.601562, -1.27734, -8.08594, 0.425049, -7.90234, 
self attn v(head): : -0.702637, -0.559082, 0.155518, -0.979492, -0.630859, 
self attn v(tail): : 0.902832, -0.150146, 0.370361, 0.0944214, 1.3877, 
self attn corr(head): : 0.992188, 0.00780869, 0.897949, 0.101929, 0.992188, 
self attn corr(tail): : 0.0572815, 0.983887, 0.0158997, 0.998535, 0.00138855, 
self attn before ffn(head): : 0.112305, -0.203003, 0.129639, -0.0809937, 0.0689697, 
self attn before ffn(tail): : -0.0330811, -0.0806274, 0.107788, 0.104309, 0.0716553, 
self attn out(head): : -0.0424194, 0.57959, 0.997559, 
self attn out(tail): : -2.93359, 3.53516, -0.0704346, 
encdec attn ln(head): : 0.00717163, 0.0722656, 0.0426636, 0.106445, -0.556641, 
encdec attn ln(tail): : -0.0995483, -0.0585938, -0.0608826, 0.0171814, -0.0618896, 
encdec attn ffn out(head): : -0.429199, -0.141846, 2.93555, 
encdec attn ffn out(tail): : -10.3438, -6.47656, 2.71484, 
ffn ln(head): : -0.159058, -0.239136, -0.00482559, -0.135254, 0.960938, 
ffn ln(tail): : 0.191284, -0.0170441, 0.0011282, -0.372803, -0.16626, 
ffn ln(head): : -1.06738, -2.90039, -0.191406, -4.08203, -131.875, 
ffn ln(tail): : -2.57422, 2.62109, -12.0781, -9.41406, 1.70508, 
self attn ln(head): : -0.0297699, -0.121582, -0.0503235, -0.142944, -0.2771, 
self attn ln(tail): : -0.0197449, 0.00447845, -0.159058, -0.197632, -0.0302277, 
self qkv(head): : -0.161011, -0.0269775, 0.549805, 0.438721, -0.560059, 
self qkv(tail): : 0.420166, 0.135132, 0.152222, -0.0543518, -0.342285, 
self attn q(head): : -0.0938721, -0.0618286, 0.701172, 0.507324, -0.45874, 
self attn q(tail): : 0.213867, -2.00195, -1.19922, 1.19727, 0.561523, 
self attn k(head): : -1.8125, 0.27002, 2.8418, -0.323242, 1.04102, 
self attn k(tail): : 0.37915, 0.679688, -2.20117, -0.397949, -1.05078, 
self attn v(head): : 0.187012, -0.192871, 0.0805054, 0.125488, -0.495117, 
self attn v(tail): : 0.521484, -0.306152, 0.0687866, -0.135254, -0.473145, 
self attn corr(head): : 0.0703125, 0.929688, 0.766602, 0.233398, 0.945312, 
self attn corr(tail): : 0.314941, 0.944824, 0.0549927, 0.765625, 0.234375, 
self attn before ffn(head): : 0.210449, -0.172363, 0.0784302, 0.0973511, -0.481445, 
self attn before ffn(tail): : 0.365723, -0.862793, -0.276855, 0.122498, 0.00453186, 
self attn out(head): : 1.24609, 0.369141, 0.45166, 
self attn out(tail): : -8.42188, -13.0312, 0.932129, 
encdec attn ln(head): : -0.0423584, 0.0393982, -0.0513, 0.0812988, -0.138794, 
encdec attn ln(tail): : -0.0215759, 0.0872192, -0.0869141, -0.22229, -0.0126648, 
encdec attn ffn out(head): : -15.2891, -2.64844, 7.05078, 
encdec attn ffn out(tail): : -11.0312, -12.5938, -10.3359, 
ffn ln(head): : -0.583984, -0.204468, -0.252441, -0.265625, 2.30859, 
ffn ln(tail): : 0.411377, 0.767578, -0.116211, -0.281738, -0.368164, 
ffn ln(head): : -21.7188, -0.394531, 4, -2.91406, -276.25, 
ffn ln(tail): : 11.875, -2.0625, -13.6016, -10.1562, -11.9297, 
self attn ln(head): : -0.401123, -0.0156403, 0.0265656, -0.0496521, -0.0425415, 
self attn ln(tail): : 0.0647583, -0.0831909, -0.102905, -0.125244, -0.151855, 
self qkv(head): : 0.22229, -0.117981, 1.69238, -0.796875, -0.14624, 
self qkv(tail): : 1.54199, -1.08105, -0.0739746, -1.19727, 0.22168, 
self attn q(head): : 0.170898, -0.350098, 1.59961, -0.570312, -0.347412, 
self attn q(tail): : -0.210938, 2.37695, -0.50293, 0.873535, 0.21814, 
self attn k(head): : 2.06641, 3.6543, 0.34668, 1.40625, 5.17969, 
self attn k(tail): : 0.615234, -1.7168, -2.84766, -5.09766, -2.62109, 
self attn v(head): : 0.132812, 0.953613, 1.71973, -0.814453, 0.0919189, 
self attn v(tail): : 1.59668, -1.44434, 0.00604248, -0.816406, 0.0490723, 
self attn corr(head): : 0.97998, 0.0198212, 0.104675, 0.895508, 0.977539, 
self attn corr(tail): : 0.174438, 0.740234, 0.259521, 0.863281, 0.136475, 
self attn before ffn(head): : 0.0229645, -0.1875, 0.199585, -0.0301361, -0.153076, 
self attn before ffn(tail): : 1.10938, -0.955078, -0.223999, -0.13147, 0.0435791, 
self attn out(head): : -20.7188, 8.08594, 7.14453, 
self attn out(tail): : -6.10547, -15.2734, -17.7656, 
encdec attn ln(head): : -0.153809, 0.0661621, 0.0125809, -0.00462723, -0.0794067, 
encdec attn ln(tail): : 0.0297241, -0.0225067, -0.0237122, -0.111328, -0.111145, 
encdec attn ffn out(head): : -36.1875, 19.0312, 28.4062, 
encdec attn ffn out(tail): : -19.1562, -18.5312, -23.7031, 
ffn ln(head): : -1.02246, 0.205078, 0.468994, -0.0760498, 0.770508, 
ffn ln(tail): : 0.346436, -0.0548401, -0.278809, -0.207642, -0.555664, 
ffn ln(head): : -33.5625, 34.0938, 25.25, -15.0312, -507.5, 
ffn ln(tail): : 4.36719, -7.5625, -17.9375, -10.9844, -23.5469, 
self attn ln(head): : -0.477051, 0.269043, 0.250488, -0.111755, 0.317871, 
self attn ln(tail): : -0.037262, -0.109802, -0.10144, -0.114258, -0.245972, 
self qkv(head): : 0.703125, -0.253174, -2.5625, -1.2041, 2.43945, 
self qkv(tail): : 1.60645, 1.11426, -0.572754, 2.29492, -2.52734, 
self attn q(head): : 0.812012, -0.255371, -2.22656, -1.19727, 2.12695, 
self attn q(tail): : 0.0427551, -0.931152, 1.05078, -1.17773, 0.771484, 
self attn k(head): : 1.56152, -9.59375, 26.5625, 11.5469, -22.2344, 
self attn k(tail): : -2.375, -0.260986, -1.85645, -1.23242, -0.794922, 
self attn v(head): : 2.21094, 2.26562, -2.66016, 2.32617, 0.513672, 
self attn v(tail): : 1.63184, 1.1084, -0.651855, 2.63867, -2.5293, 
self attn corr(head): : 0.44751, 0.552734, 0.463867, 0.536133, 0.17334, 
self attn corr(tail): : 0.760742, 0.859863, 0.140381, 0.916504, 0.0836792, 
self attn before ffn(head): : 1.60449, 1.43164, -1.83887, 1.8291, 0.245239, 
self attn before ffn(tail): : 1.17676, 1.22852, -0.0748901, 0.556641, -1.76855, 
self attn out(head): : -24.5938, 39.1562, 36.8125, 
self attn out(tail): : -18.1562, -0.796875, -26.3594, 
encdec attn ln(head): : -0.129761, 0.191528, 0.150513, -0.0657349, 0.0808105, 
encdec attn ln(tail): : -0.0232544, -0.0589294, -0.051178, -0.0377197, -0.142334, 
encdec attn ffn out(head): : -8.71875, 41.625, 47.0312, 
encdec attn ffn out(tail): : -34.9375, -0.237305, -39.5625, 
ffn ln(head): : -0.236084, 0.501953, 0.566406, -0.311279, -4.95312, 
ffn ln(tail): : 0.808594, 0.031311, -0.581055, -0.0772095, -0.689453, 
ffn ln(head): : -7.90625, 34.625, 62.75, -32.25, -469.25, 
ffn ln(tail): : 29.5781, -24.3438, -33.6875, 4.10156, -42.8438, 
decoder output: batch-0, beam-0
hidden: -0.431641, 1.49023, 1.92285, -1.04004, 3.76367, -2.27734, -1.25293, 0.578613, 0.962402, -0.238647, 
logits: -59.9688, -61.875, -57.875, -57.5625, -64.125, -63.9375, -65.8125, -59.9375, -59.9375, -65.8125, 
ker_topk_sample_launcher with _cur_step=1  _max_step=64  _max_thread_per_block=256
### in ker_topk_sample_launcher 
### out ker_topk_sample_launcher 
unfinished flag: 1, 
Batch token ids: : 5001, 1, 2, 
*** run step 2 ***
decoder emb: batch-0, beam-0
emb: 0.68457, 0.424805, 0.863281, 1.31445, -19.625, 1.75684, 2.55078, 1.36328, 4.60156, 1.62305, 
self attn ln(head): : 0.196167, 0.0939331, 0.141113, 0.320312, -0.0569458, 
self attn ln(tail): : -0.227295, 0.0446777, 0.216064, 0.065979, 0.0857544, 
self qkv(head): : 2.72852, 0.605469, 0.579102, -0.915527, -1.03125, 
self qkv(tail): : -1.41113, -1.23047, -0.00194359, 0.903809, -0.604492, 
self attn q(head): : 2.85938, 0.540039, 0.34375, -0.995605, -1.10742, 
self attn q(tail): : 0.599609, -1.76465, 0.0936279, -1.32617, -0.401123, 
self attn k(head): : -0.520508, 2.75391, -0.978516, 0.845215, -1.72754, 
self attn k(tail): : -0.936035, -1.42188, -7.64062, -0.606934, -7.06641, 
self attn v(head): : 0.638672, 0.440186, 1.44727, 0.155029, 0.274658, 
self attn v(tail): : -1.48828, -1.2793, 0.0944214, 0.88916, -0.408936, 
self attn corr(head): : 0.164185, 0.831543, 0.00428772, 0.572266, 0.409912, 
self attn corr(tail): : 0.0394287, 0.00550461, 0.999023, 0.000816345, 0.000269175, 
self attn before ffn(head): : -0.562012, -0.49585, 0.156738, -0.826172, -0.51123, 
self attn before ffn(tail): : -0.0340271, -0.0809326, 0.107666, 0.104553, 0.0708008, 
self attn out(head): : 1.06055, 0.851074, 2.57031, 
self attn out(tail): : 0.623047, 2.23242, -0.119141, 
encdec attn ln(head): : 0.0916748, 0.079895, 0.140381, 0.062561, -0.558105, 
encdec attn ln(tail): : -0.0092392, 0.0414124, 0.0638428, -0.0402222, -0.0680542, 
encdec attn ffn out(head): : 0.575684, 0.568359, 4.40234, 
encdec attn ffn out(tail): : -9.03125, -8.41406, 0.648438, 
ffn ln(head): : 0.00663376, -0.144775, 0.135498, -0.164917, 0.9375, 
ffn ln(tail): : 0.374023, 0.35376, 0.0504761, -0.428223, -0.250977, 
ffn ln(head): : 4.33594, 0.251953, 3.49219, 1.37695, -140.75, 
ffn ln(tail): : 6.22266, 16.2188, -10.2031, -10.3594, -1.12012, 
self attn ln(head): : 0.163574, -0.00385094, 0.0774536, 0.0334167, -0.324219, 
self attn ln(tail): : 0.0895996, 0.22937, -0.129028, -0.210205, -0.0757446, 
self qkv(head): : 0.778809, 0.000359774, 0.787109, 1.21582, -1.22461, 
self qkv(tail): : 0.991699, 0.0882568, -0.0841675, 0.128174, -0.0402527, 
self attn q(head): : 0.845703, -0.0344849, 0.938477, 1.28418, -1.12305, 
self attn q(tail): : 0.149536, -1.64648, -1.09277, 0.235107, 0.114502, 
self attn k(head): : -1.45312, 0.76123, 2.96875, -0.216797, 1.0957, 
self attn k(tail): : 1.62695, 0.0585938, -1.60254, -0.619629, -1.18164, 
self attn v(head): : 0.759277, 0.504883, -0.810547, 0.247681, -0.716797, 
self attn v(tail): : 1.09277, -0.353027, -0.167603, 0.0473022, -0.171021, 
self attn corr(head): : 0.0560303, 0.528809, 0.415283, 0.646484, 0.253906, 
self attn corr(tail): : 0.0653687, 0.119324, 0.245972, 0.452393, 0.301758, 
self attn before ffn(head): : 0.443359, 0.11322, -0.29126, 0.153809, -0.57666, 
self attn before ffn(tail): : 0.644043, -0.499268, -0.113586, 0.00262833, -0.228516, 
self attn out(head): : 9.79688, 6.32812, 4.78125, 
self attn out(tail): : -4.23438, -15.9062, -3.2168, 
encdec attn ln(head): : 0.0675049, 0.141357, 0.0126114, 0.227661, -0.144043, 
encdec attn ln(tail): : 0.105042, 0.274658, -0.0263977, -0.255371, -0.0667725, 
encdec attn ffn out(head): : -15.4141, -1.47656, 20.3125, 
encdec attn ffn out(tail): : -4.82812, -25.5, -11.1484, 
ffn ln(head): : -0.570801, -0.165161, 0.224121, 0.435303, 2.42773, 
ffn ln(tail): : 0.754395, 1.47266, 0.0506897, -0.65332, -0.380615, 
ffn ln(head): : -16.75, 4.37891, 19.2969, 21.5625, -253, 
ffn ln(tail): : 26.5, 20.9062, -0.818359, -25.7812, -15.9062, 
self attn ln(head): : -0.31543, 0.0587769, 0.255371, 0.31665, 0.0259552, 
self attn ln(tail): : 0.190063, 0.148193, 0.0276794, -0.290283, -0.19104, 
self qkv(head): : -0.0171967, -0.368896, 2.04883, -0.484863, -0.00930786, 
self qkv(tail): : 2.04102, -1.24512, 0.47168, -0.432617, -0.380371, 
self attn q(head): : -0.0685425, -0.601074, 1.95605, -0.258301, -0.210449, 
self attn q(tail): : 0.46167, 2.0957, -0.418213, 0.480957, 0.3125, 
self attn k(head): : 2.87109, 3.66211, 0.371582, 1.34375, 5.19141, 
self attn k(tail): : 1.31348, -2.26562, -2.30273, -5.57031, -2.01758, 
self attn v(head): : 0.655762, 1.70215, 1.70312, -0.226074, 0.635742, 
self attn v(tail): : 2.0957, -1.6084, 0.551758, -0.052002, -0.552734, 
self attn corr(head): : 0.967773, 0.0263977, 0.00585556, 0.079834, 0.370605, 
self attn corr(tail): : 0.120483, 0.359375, 0.469482, 0.385986, 0.144531, 
self attn before ffn(head): : 0.0274353, -0.168701, 0.21875, -0.0366516, -0.146851, 
self attn before ffn(tail): : 1.4043, -1.20215, -0.0402222, -0.333496, -0.0408936, 
self attn out(head): : -15.5547, 12.1016, 24.5469, 
self attn out(tail): : 8.78125, -30.6562, -21.875, 
encdec attn ln(head): : -0.11615, 0.090271, 0.105408, 0.163208, -0.0402222, 
encdec attn ln(tail): : 0.108459, 0.0792236, 0.0455322, -0.18457, -0.129395, 
encdec attn ffn out(head): : -40.7812, 27.7656, 52.4375, 
encdec attn ffn out(tail): : 4.53906, -41.6875, -19.7188, 
ffn ln(head): : -1.1084, 0.413818, 1.10156, 0.685547, 0.859375, 
ffn ln(tail): : 0.844727, 0.407959, 0.222778, -0.71875, -0.450439, 
ffn ln(head): : -35.375, 46.2812, 55.5625, 24.5312, -515, 
ffn ln(tail): : 30.4688, 8.63281, 7.17969, -31.9688, -19.4062, 
self attn ln(head): : -0.476074, 0.364014, 0.509277, 0.233398, 0.348877, 
self attn ln(tail): : 0.125488, 0.00751114, 0.103271, -0.256104, -0.204224, 
self qkv(head): : 0.628418, -0.184082, -2.90234, -1.68555, 2.29492, 
self qkv(tail): : 1.0957, 1.75781, -1.41699, 2.50195, -3.25195, 
self attn q(head): : 0.737305, -0.186401, -2.56641, -1.67871, 1.98145, 
self attn q(tail): : -0.288086, -0.72998, 1.48438, -1.2627, 1.04395, 
self attn k(head): : 1.88965, -8.9375, 27.1562, 11.5547, -20.9688, 
self attn k(tail): : -2.25977, -0.748047, -1.96094, -1.54297, -0.699707, 
self attn v(head): : 2.17969, 2.40625, -2.44531, 1.98535, 0.9375, 
self attn v(tail): : 1.12109, 1.75195, -1.49609, 2.8457, -3.25391, 
self attn corr(head): : 0.352539, 0.316162, 0.331299, 0.172607, 0.136963, 
self attn corr(tail): : 0.11084, 0.119812, 0.809082, 0.0994873, 0.0914307, 
self attn before ffn(head): : 1.72266, 1.65527, -1.94141, 1.82129, 0.442627, 
self attn before ffn(tail): : 1.18262, 1.27344, -0.219604, 0.819336, -1.92285, 
self attn out(head): : -21.75, 51.7812, 66.25, 
self attn out(tail): : 7.64453, -21.625, -19.375, 
encdec attn ln(head): : -0.103271, 0.229736, 0.260254, 0.0998535, 0.0828247, 
encdec attn ln(tail): : 0.0825806, -0.00328064, 0.0484619, -0.105652, -0.109253, 
encdec attn ffn out(head): : -2.0625, 54.4062, 80.625, 
encdec attn ffn out(tail): : -10.1328, -27.6719, -29.5469, 
ffn ln(head): : -0.110596, 0.641113, 1.07227, 0.372559, -4.92188, 
ffn ln(tail): : 1.36328, 0.185791, -0.136719, -0.503906, -0.415039, 
ffn ln(head): : 0.154297, 51.6562, 83.5625, 7.51953, -374.25, 
ffn ln(tail): : 64.625, -14.6172, -4.43359, -24.4688, -39.0938, 
decoder output: batch-0, beam-0
hidden: -0.0324097, 2.07617, 2.44336, 0.49707, 3.16016, -2.32617, -1.69824, 0.147583, 0.633301, -0.501953, 
logits: -67.25, -70.875, -68.25, -61.7188, -68.3125, -72, -73.1875, -67.25, -67.25, -73.625, 
ker_topk_sample_launcher with _cur_step=2  _max_step=64  _max_thread_per_block=256
### in ker_topk_sample_launcher 
### out ker_topk_sample_launcher 
unfinished flag: 1, 
Batch token ids: : 5001, 1, 2, 3, 
*** run step 3 ***
decoder emb: batch-0, beam-0
emb: 0.190796, 0.780273, 1.53027, -0.128418, -15.8906, 0.801758, -1.86133, -0.0830078, 4.04297, 1.44043, 
self attn ln(head): : 0.0478821, 0.219971, 0.304688, -0.0388794, -0.0300598, 
self attn ln(tail): : -0.243164, 0.252197, 0.135132, -0.109009, -0.198608, 
self qkv(head): : -0.42334, 0.1604, -0.0794067, 1.25391, -0.940918, 
self qkv(tail): : 1.16309, 0.782227, 0.592773, -0.414307, 0.0583801, 
self attn q(head): : -0.291748, 0.0949707, -0.314697, 1.17383, -1.01758, 
self attn q(tail): : 0.719727, 1.06543, 0.407959, 1.7334, 0.397949, 
self attn k(head): : 0.895508, 1.94434, -0.894043, 0.0322266, -2.09766, 
self attn k(tail): : -1.01953, -1.56055, -8.75781, 3.68359, -7.52734, 
self attn v(head): : 0.226807, -0.332031, 0.200928, 0.616211, -1.31738, 
self attn v(tail): : 1.08594, 0.733398, 0.688965, -0.428955, 0.253906, 
self attn corr(head): : 0.720215, 0.0142441, 0.244019, 0.0215454, 0.772461, 
self attn corr(tail): : 0.00126362, 0.18335, 0.000219703, 0.00141048, 0.814941, 
self attn before ffn(head): : 0.236206, -0.0518799, 0.452881, -0.0160828, 0.083252, 
self attn before ffn(tail): : 0.876953, 0.581055, 0.581543, -0.329102, 0.219482, 
self attn out(head): : 0.349121, 0.643555, 1.69043, 
self attn out(tail): : 1.79102, -1.01758, -1.23047, 
encdec attn ln(head): : 0.0328369, 0.0661621, 0.0842285, -0.0458984, -0.554688, 
encdec attn ln(tail): : -0.081604, 0.168335, 0.107422, -0.149658, -0.106689, 
encdec attn ffn out(head): : -0.172363, 0.17041, 3.89062, 
encdec attn ffn out(tail): : -6.14453, -14.5859, -2.80078, 
ffn ln(head): : -0.118164, -0.197266, 0.081665, -0.350098, 0.899902, 
ffn ln(tail): : 0.372559, 0.381104, 0.152222, -0.602539, -0.377441, 
ffn ln(head): : 2.99023, 0.734863, 2.76562, -0.562012, -133.75, 
ffn ln(tail): : 5.45703, 17.7031, -10.1719, -18.1094, -3.99219, 
self attn ln(head): : 0.116455, 0.0128021, 0.052948, -0.0309906, -0.302002, 
self attn ln(tail): : 0.0813599, 0.261475, -0.133667, -0.340332, -0.12384, 
self qkv(head): : -0.724121, 0.256592, 0.794922, -0.106201, -0.617676, 
self qkv(tail): : 0.791016, -0.165527, -0.172852, 0.177856, 0.675781, 
self attn q(head): : -0.657227, 0.22168, 0.946289, -0.0377197, -0.516113, 
self attn q(tail): : 0.849121, -1.5332, -0.202148, 0.547363, 0.20813, 
self attn k(head): : -1.51758, 0.445801, 2.07812, -0.649414, 0.422363, 
self attn k(tail): : 1.39062, 1.10156, -1.64062, -1.03027, -0.388916, 
self attn v(head): : 1.00098, 0.261475, -0.492676, -0.33252, -0.467529, 
self attn v(tail): : 0.89209, -0.606934, -0.256348, 0.0969849, 0.544922, 
self attn corr(head): : 0.0561829, 0.499023, 0.245972, 0.198853, 0.53418, 
self attn corr(tail): : 0.081543, 0.202393, 0.205444, 0.367188, 0.224976, 
self attn before ffn(head): : 0.508301, 0.0855103, -0.254395, 0.0419922, -0.533203, 
self attn before ffn(tail): : 0.773438, -0.538086, -0.182495, 0.0521545, -0.00689697, 
self attn out(head): : 8.70312, 5.76953, 4.10938, 
self attn out(tail): : -4.10156, -23.75, -7.26953, 
encdec attn ln(head): : 0.054718, 0.132568, 0.00292778, 0.188232, -0.0813599, 
encdec attn ln(tail): : 0.101868, 0.297607, -0.0263672, -0.363281, -0.121643, 
encdec attn ffn out(head): : -8.91406, -4.5, 13.0781, 
encdec attn ffn out(tail): : -4.70703, -35.125, -19.2031, 
ffn ln(head): : -0.376465, -0.262939, -0.0229492, 0.220093, 2.37695, 
ffn ln(tail): : 0.740723, 1.57422, 0.0507507, -0.975098, -0.624512, 
ffn ln(head): : -13.8438, 2.01172, 8.54688, 17.9375, -258.75, 
ffn ln(tail): : 25.5625, 19.0938, -0.425781, -33.6562, -23.7812, 
self attn ln(head): : -0.265381, 0.0233459, 0.0964966, 0.26416, 0.00680542, 
self attn ln(tail): : 0.183228, 0.131226, 0.0323181, -0.374268, -0.269531, 
self qkv(head): : -0.0924683, 0.107483, 0.920898, -0.777344, -0.556152, 
self qkv(tail): : 2.13867, -1.08301, -0.0808105, -0.431396, -0.0887451, 
self attn q(head): : -0.143799, -0.124573, 0.828125, -0.550781, -0.757324, 
self attn q(tail): : 0.733887, 1.16309, -0.179077, 0.675293, -0.723633, 
self attn k(head): : 2.19727, 3.44727, 0.421875, 1.60938, 4.98438, 
self attn k(tail): : 0.954102, -1.92383, -2.18359, -5.61719, -2.57422, 
self attn v(head): : 0.581055, 0.470215, 2.04297, -0.323975, -0.0976562, 
self attn v(tail): : 2.19336, -1.44629, -0.000793457, -0.0507812, -0.26123, 
self attn corr(head): : 0.944824, 0.0259552, 0.0120239, 0.0172882, 0.0921631, 
self attn corr(tail): : 0.233887, 0.0350342, 0.160156, 0.405029, 0.399902, 
self attn before ffn(head): : 0.0409851, -0.14563, 0.26001, -0.0429382, -0.140991, 
self attn before ffn(tail): : 2.01758, -1.49219, 0.214966, -0.172974, -0.319092, 
self attn out(head): : -12.1641, 9.41406, 14.3281, 
self attn out(tail): : 9.83594, -37, -28.0312, 
encdec attn ln(head): : -0.0903931, 0.0731201, 0.0493164, 0.140137, -0.0563354, 
encdec attn ln(tail): : 0.0969238, 0.0673218, 0.0497131, -0.209595, -0.155518, 
encdec attn ffn out(head): : -29.2812, 13.7656, 27.5938, 
encdec attn ffn out(tail): : -4.17969, -45.7812, -32.25, 
ffn ln(head): : -0.803223, 0.0545959, 0.408691, 0.42334, 0.787598, 
ffn ln(tail): : 0.88916, 0.150269, 0.0472412, -0.77832, -0.703613, 
ffn ln(head): : -28.5625, 31.1562, 29.7031, 18.0469, -544, 
ffn ln(tail): : 32.4375, -0.550781, 2.98438, -37.5312, -28.4531, 
self attn ln(head): : -0.393066, 0.223999, 0.275635, 0.175781, 0.317383, 
self attn ln(tail): : 0.134277, -0.0563049, 0.0704956, -0.289795, -0.268066, 
self qkv(head): : 1.3252, 0.0630493, -1.9707, -1.64355, 2.11133, 
self qkv(tail): : 0.211914, 1.44336, -0.326172, 1.6416, -1.95801, 
self attn q(head): : 1.43359, 0.0607605, -1.63477, -1.63672, 1.79785, 
self attn q(tail): : 0.0110779, -0.798828, 0.831543, -0.479248, 1.0791, 
self attn k(head): : 2.03711, -9.76562, 27.1875, 11.1328, -21.375, 
self attn k(tail): : -1.68945, -0.113525, -1.8418, -1.7168, -0.572754, 
self attn v(head): : 1.33691, 1.97168, -2.38867, 1.86328, 0.564453, 
self attn v(tail): : 0.237793, 1.4375, -0.405029, 1.98633, -1.95996, 
self attn corr(head): : 0.34375, 0.245605, 0.225342, 0.185425, 0.115479, 
self attn corr(tail): : 0.170898, 0.513184, 0.137451, 0.141113, 0.208374, 
self attn before ffn(head): : 1.57617, 1.60254, -1.93066, 1.78223, 0.412354, 
self attn before ffn(tail): : 1.01465, 1.33496, -0.396484, 1.36621, -2.08594, 
self attn out(head): : -17.0312, 35.3125, 40.4375, 
self attn out(tail): : 1.77246, -26.6094, -27.375, 
encdec attn ln(head): : -0.0778809, 0.160522, 0.150635, 0.078064, 0.0495605, 
encdec attn ln(tail): : 0.0874634, -0.0281372, 0.02742, -0.120667, -0.135376, 
encdec attn ffn out(head): : -4.90625, 41.25, 50.625, 
encdec attn ffn out(tail): : -11.2422, -32.125, -34.9375, 
ffn ln(head): : -0.153564, 0.424316, 0.533203, 0.239746, -5.19531, 
ffn ln(tail): : 1.39844, 0.103149, -0.147949, -0.558105, -0.499756, 
ffn ln(head): : -3.94141, 45.875, 51.0625, 10.8359, -573, 
ffn ln(tail): : 67.1875, -11, 3.86719, -35.7188, -37.0625, 
decoder output: batch-0, beam-0
hidden: -0.213013, 1.78906, 1.38379, 0.605469, 4.01953, -2.28711, -1.12598, -0.0197601, 0.430176, -0.970215, 
logits: -58.0312, -62.625, -62.375, -55.9062, -55.9375, -60.875, -63.75, -58.0312, -58.0312, -64.625, 
ker_topk_sample_launcher with _cur_step=3  _max_step=64  _max_thread_per_block=256
### in ker_topk_sample_launcher 
### out ker_topk_sample_launcher 
unfinished flag: 1, 
Batch token ids: : 5001, 1, 2, 3, 4, 
one infer time duration time is: 79.5837 ms
Transformer output shape: 1 1 5 
Transformer output shape: 1 1 
(base) ]0;poweruser@s-113-1-1: ~/junda.feng/ixinfer/TransformerInfer/build[01;32mpoweruser@s-113-1-1[00m:[01;34m~/junda.feng/ixinfer/TransformerInfer/build[00m$ exit
exit

Script done on 2022-10-12 22:23:16+0800
